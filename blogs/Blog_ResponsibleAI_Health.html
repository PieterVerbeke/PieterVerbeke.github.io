<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Responsible AI in healthcare- Blog Post</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
    <script src="https://kit.fontawesome.com/ec75bccfcd.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="blog-style.css">
</head>

<body id="pagetop">
    <nav class="navbar navbar-expand-lg navbar-dark bg-secondary fixed-top" id="sideNav" style="min-height: 75px; padding-left:50px; padding-top: 15px; background-color:#CD5C5C;">
      <a class="navbar-brand" href=#pagetop>
        <span class="d-block d-lg-none">Pieter Verbeke</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.jpg" alt="">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link" href="../index.html" style="color: #FFFFFF;">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../Academic work.html" style="color: #FFFFFF;">Academic work</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../Applied projects.html" style="color: #FFFFFF;">Applied projects</a>
          </li>
          <li class="nav-item active"><a class="nav-link" href="../Professional experience.html">Professional experience</a></li>
          <li class="nav-item active"><a class="nav-link" href="../Blogs.html">Blogs</a></li>
        </ul>
      </div>
    </nav>

    <div class="container" style="background-color:#FFEBCD;">
        <h1 style = "color:inherit; text-align:center; padding-top: 125px;">The Double-Edged Scalpel: Using AI Responsibly in Healthcare</h1>
        <p class="tags">#ResponsibleAI #RAG #AgenticAI #Healthcare</p>

        <article>
            <p>There’s a lot of excitement—and concern—about the role of AI in healthcare these days. Headlines highlight advances like <a href = https://www.nature.com/articles/s44401-024-00004-1>Retrieval-Augmented Generation (RAG) systems promising more reliable outputs</a> and personal AI wellness coaches guiding people to healthier lifestyles. But amidst this buzz, I can’t help but feel we’re headed down a risky path.</p>
            <p>AI has the potential to revolutionize healthcare, but only if we use it wisely. I believe AI shines most when it acts as an assistant to experts, not as a replacement. For instance, AI algorithms that help radiologists detect anomalies in scans or identify patterns in medical data can be life-saving. They catch what even the most trained human eye might miss, improving diagnosis and outcomes.</p>
            <p>But when we cross the line from using AI as a tool to making it a direct communicator with patients—or worse, an autonomous decision-maker—we step into dangerous territory.</p>

            <h2><strong>The Myth of “Fixing” AI Bias and Hallucinations</strong></h2>
            <p>One of the biggest arguments for systems like RAG is that they can reduce AI’s tendency to “hallucinate” or present biased information. But here’s the truth: we can’t fully eliminate these issues because they’re not just AI problems—they’re societal ones.</p>
            <p>AI learns from us—our data, our histories, our imperfections. <strong>Biases in AI reflect biases in society</strong>. Although we can be aware of some biases that are present in our data, everyone carries unconscious biases. Expecting AI to somehow rise above this is unrealistic. What’s more troubling is that AI can sometimes amplify these biases, spreading misinformation at scale without any sense of accountability.</p> 
            <p>Indeed, as has been elaborately described in <a href = https://arxiv.org/abs/2409.05746>a recent article</a>, a lot of hallucinations are structural and cannot be eliminated. They exist as a natural consequence of the data and the models, which are never 100% correct or entirely bias-free.</p>
            
            <h2><strong>The Rise of Agentic AI and AI Coaches</strong></h2>
            <p>Another revolution in AI is the rise of AI agents. Here, a combination of multiple AI systems that can work in parallel or sequentially allow the agent to act autonomously, pursue goals, make decisions, and execute actions with a certain level of independence, often without continuous human input. The wellness industry, in particular, seems eager to embrace AI as a personal coach or even a quasi-therapist. </p>
            <p>However, also these autonomous agents cannot solve the hallucination issues. Furthermore, they raise the <strong>issue of responsibility</strong>. In healthcare, the stakes are incredibly high. Lives are on the line. AI can support experts by providing data-driven insights, but it should never replace the human responsibility that comes with making decisions about someone’s health.</p>
            <p>Furthermore, we need to remember that AI is a reflection of us—our knowledge, our flaws, our society. Such as for instance <strong>the issue of expertise </strong> where evidence-based expertise from well-trained professionals gets devalued by the growing numbers of inadequately trained support.</p>
            <p>Although often with good intentions, some people seem to believe that anyone can be a therapist or a coach. This is problematic since not all these coaches and therapists are adequately trained. Some base themselves purely on personal experience and what they find on the internet. When we introduce AI into this mix—trained on a blend of science, opinion, and internet chatter—it risks reinforcing this lack of rigor.</p>
        
            <h2><strong>I Want AI to Do My Laundry and Dishes</strong></h2>
            <p>A famous quote in the pursuit of what AI should do next comes from writer Joanna Maciejewska, who said, “I want AI to do my laundry and dishes, not my writing.” Although we are often amazed by the things AI can do, we should still ask ourselves whether this will make our lives better. We want AI to take over the things we don’t like such that there is more time for the things we love.</p>
            <p>As it turns out, professionals in the healthcare sector do not want AI to take over caregiving; they love to take care of their patients. They want AI to take over their administration. <a href = https://www.vrt.be/vrtnws/nl/2025/02/10/waar-gebruiken-we-ai-op-de-werkvloer/ >A perfect example was featured in Belgian news recently</a>, where they are exploring AI as a note-taker during medical consultations. This gives medical doctors the freedom to focus more on their patients and less on administration.</p>

            <h2><strong>Let’s Use AI Thoughtfully</strong></h2>
            <p>AI holds incredible promise in healthcare, but we must use it responsibly. It should enhance human expertise, not sideline it. We need to focus not just on improving AI but also on addressing the deeper societal issues—bias, misinformation, and the devaluation of expertise—that it can unintentionally magnify.</p>
            <p>Healthcare demands empathy, accountability, and human judgment. AI can be a powerful ally, but it should never replace the people we trust with our health.</p>

            <h4>Links to the sources</h4>
            <ul>
                <li>Retrieval-Augmented Generation (RAG) systems in healthcare: <a href = https://www.nature.com/articles/s44401-024-00004-1>https://www.nature.com/articles/s44401-024-00004-1></a></li>
                <li>Why Generative AI will always hallucinate: <a href = https://arxiv.org/abs/2409.05746>https://arxiv.org/abs/2409.05746</a></li>
                <li>AI as a note-taker during medical consultations<a href = https://www.vrt.be/vrtnws/nl/2025/02/10/waar-gebruiken-we-ai-op-de-werkvloer/>https://www.vrt.be/vrtnws/nl/2025/02/10/waar-gebruiken-we-ai-op-de-werkvloer/</a></li>
        </article>
    </div>
</body>
</html>